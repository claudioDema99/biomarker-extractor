{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1b14ad",
   "metadata": {},
   "source": [
    "Per fare un estrazione accurata, dobbiamo riempire i campi del dizionario \"databases\" all'interno di src/prompts.py  \n",
    "Ci servono 3 campi:\n",
    "- name: il nome della patologia che sarà riportata nei prompts\n",
    "- examples: semplice lista di 3/4 markers/biomarkers legati alla patologia\n",
    "- shots: esempio di input da dare al modello e output ottimale che vorremmo ottenere (importante!!)  \n",
    "\n",
    "Vedere file shots/SHOTS_ALZHEIMER per esempio e file shots/shots.txt per template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37705c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "from src.models import get_token_count\n",
    "\n",
    "def remove_duplicate_lines_in_cell(cell_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Rimuove righe duplicate all'interno di una cella dopo aver rimosso \n",
    "    i prefissi numerici e le sigle OG###.\n",
    "    \n",
    "    Pattern da rimuovere: \"numero - OG###: \" all'inizio di ogni riga\n",
    "    Esempio: \"898604142 - OG000: Treatment Engagement\" -> \"Treatment Engagement\"\n",
    "    \n",
    "    Ignora il \";\" finale quando confronta le righe per duplicati.\n",
    "    \n",
    "    Args:\n",
    "        cell_content (str): Il contenuto della cella da processare\n",
    "        \n",
    "    Returns:\n",
    "        str: Il contenuto della cella con prefissi rimossi e righe duplicate eliminate\n",
    "    \"\"\"\n",
    "    if pd.isna(cell_content) or not isinstance(cell_content, str):\n",
    "        return cell_content\n",
    "    \n",
    "    lines = cell_content.strip().split('\\n')\n",
    "    if len(lines) <= 1:\n",
    "        # Anche per una singola riga, rimuovi il prefisso se presente\n",
    "        if len(lines) == 1:\n",
    "            cleaned_line = _remove_prefix_from_line(lines[0])\n",
    "            return cleaned_line if cleaned_line.strip() else cell_content\n",
    "        return cell_content\n",
    "    \n",
    "    # Set per tenere traccia delle righe già viste (dopo pulizia e normalizzazione)\n",
    "    seen_normalized_lines = set()\n",
    "    result_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Salta righe vuote\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Rimuovi il prefisso \"numero - OG###: \" dalla riga\n",
    "        cleaned_line = _remove_prefix_from_line(line)\n",
    "        \n",
    "        # Se la riga pulita è vuota, salta\n",
    "        if not cleaned_line.strip():\n",
    "            continue\n",
    "        \n",
    "        # Normalizza la riga per il confronto: rimuovi \";\" finale se presente\n",
    "        normalized_line = _normalize_line_for_comparison(cleaned_line)\n",
    "        \n",
    "        # Aggiungi solo se non già vista (confronto normalizzato)\n",
    "        if normalized_line not in seen_normalized_lines:\n",
    "            seen_normalized_lines.add(normalized_line)\n",
    "            result_lines.append(cleaned_line)  # Mantieni la riga originale pulita\n",
    "    \n",
    "    return '\\n'.join(result_lines)\n",
    "\n",
    "def _normalize_line_for_comparison(line: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizza una riga per il confronto di duplicati rimuovendo il \";\" finale.\n",
    "    \n",
    "    Questo permette di considerare uguali righe che differiscono solo per \n",
    "    la presenza/assenza del punto e virgola finale.\n",
    "    \n",
    "    Args:\n",
    "        line (str): La riga da normalizzare\n",
    "        \n",
    "    Returns:\n",
    "        str: La riga normalizzata (senza \";\" finale)\n",
    "    \"\"\"\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Rimuovi \";\" finale se presente\n",
    "    if line.endswith(';'):\n",
    "        return line[:-1].strip()\n",
    "    \n",
    "    return line\n",
    "\n",
    "def _remove_prefix_from_line(line: str) -> str:\n",
    "    \"\"\"\n",
    "    Rimuove il prefisso \"numero - OG###: \" da una singola riga.\n",
    "    \n",
    "    Pattern: numeri seguiti da \" - OG\" + numeri + \": \"\n",
    "    Esempi:\n",
    "    - \"898604142 - OG000: Treatment Engagement\" -> \"Treatment Engagement\"\n",
    "    - \"898604143 - OG001: Treatment Engagement\" -> \"Treatment Engagement\"\n",
    "    \n",
    "    Args:\n",
    "        line (str): La riga da cui rimuovere il prefisso\n",
    "        \n",
    "    Returns:\n",
    "        str: La riga senza prefisso\n",
    "    \"\"\"\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Pattern per catturare: numero - OG + numeri + : + contenuto\n",
    "    # Gruppo 1: cattura tutto dopo \"OG###: \"\n",
    "    pattern = r'^\\d+\\s*-\\s*OG\\d+\\s*:\\s*(.+)$'\n",
    "    match = re.match(pattern, line)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        # Se il pattern non corrisponde, restituisci la riga originale\n",
    "        return line\n",
    "\n",
    "def process_batch_for_deduplication(batch_df: pd.DataFrame, \n",
    "                                  columns_to_process: List[str] = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Processa un batch di righe del DataFrame rimuovendo i prefissi e le righe duplicate \n",
    "    nelle colonne specificate.\n",
    "    \n",
    "    Args:\n",
    "        batch_df (pd.DataFrame): Il batch di righe da processare\n",
    "        columns_to_process (List[str], optional): Lista delle colonne da processare. \n",
    "                                                Se None, processa tutte le colonne.\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: Lista di record con contenuti puliti e deduplicati\n",
    "    \"\"\"\n",
    "    # Crea una copia del batch per non modificare l'originale\n",
    "    processed_batch = batch_df.copy()\n",
    "    \n",
    "    # Se non specificate, processa tutte le colonne\n",
    "    if columns_to_process is None:\n",
    "        columns_to_process = processed_batch.columns.tolist()\n",
    "    \n",
    "    # Applica la pulizia e deduplicazione solo alle colonne specificate\n",
    "    for col in columns_to_process:\n",
    "        if col in processed_batch.columns:\n",
    "            processed_batch[col] = processed_batch[col].apply(remove_duplicate_lines_in_cell)\n",
    "    \n",
    "    # Converti in dizionario di record\n",
    "    return processed_batch.to_dict(orient=\"records\")\n",
    "\n",
    "def write_debug(file_name, df, target_indices):\n",
    "    with open(file_name, 'a', encoding='utf-8') as file:\n",
    "        # Scrivi ogni riga\n",
    "        for index, row in df.iterrows():\n",
    "            file.write(f\"Riga {target_indices[index]}:\\n\")\n",
    "            for col in df.columns:\n",
    "                file.write(f\"  {col}: {row[col]}\\n\")\n",
    "            file.write('\\n___________________________________________________\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18cdd9",
   "metadata": {},
   "source": [
    "Estrae e preprocessa le righe degli indici indicati in target_indeces, e le salva nel file file_name  \n",
    "Useremo queste righe per fornire gli esempi (shots) da dare nei prompt all'LLM per l'estrazione dei biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d91ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"\"\n",
    "target_indices = [0, 1, 200, 300]\n",
    "\n",
    "df = pd.read_csv(\"../data/Alzheimer_1row_Puri.csv\")\n",
    "cols_to_keep = [\n",
    "    #\"study_type-intervention_type\",\n",
    "    \"brief_summary\",\n",
    "    \"detailed_description\",\n",
    "    \"outcome_measurement_title\",\n",
    "    \"outcome_measurement_description\"\n",
    "]\n",
    "df = df[cols_to_keep].dropna(how=\"all\")\n",
    "# Estrazione delle righe con indici specifici\n",
    "extracted_rows = df.iloc[target_indices]\n",
    "df = pd.DataFrame(process_batch_for_deduplication(extracted_rows))\n",
    "write_debug(file_name, df, target_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a046ea",
   "metadata": {},
   "source": [
    "Mi servono questo formato di \"examples\" da fornire ad un LLM per l'analisi ed estrazione di biomarkers da un database enorme.\n",
    "Guarda l'allegato \"esempi.txt\" per capire il formato: ogni esempio ha un input formato da quattro parametri, esattamente \"brief_summary\", \"detailed_description\", \"outcome_measurement_title\" e \"outcome_measurement_description\", e da queste informazioni l'LLM dovrtebbe estrarre una breve analisi da inserire nel file json all'interno della key \"analysis\", e una lista dei biomarcatori identificati (coerente con l'analisi) nella key \"biomarkers\", rispettando la sintassi \"ACRONIMO: expanded form of the acronym\".\n",
    "Prova ad applicare la stessa analisi ed estrazione di biomarker al seguente input record."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
